{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 8) (100000, 8)\n",
      "(100000, 8) (200000, 8)\n",
      "(100000, 8) (300000, 8)\n",
      "(100000, 8) (400000, 8)\n",
      "(100000, 8) (500000, 8)\n"
     ]
    }
   ],
   "source": [
    "# df_main = pd.DataFrame()\n",
    "\n",
    "# for input_path in sorted(glob.glob(\"data/inputs/*_response.csv\")):\n",
    "#     df = pd.read_csv(input_path)\n",
    "#     df_main = pd.concat([df_main, df], axis=0, ignore_index=True)\n",
    "#     print(df.shape, df_main.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Batch from 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all urls from 001 file, read all links in batch 1 and batch 2, concat them, compare with 001 and get common urls\n",
    "\n",
    "# now filter 001 file by removing common urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 8)\n",
      "(46333, 1)\n",
      "(41535, 1)\n",
      "Index(['source_url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_input = pd.read_csv('data/inputs/100k_response - 100k_response.csv')\n",
    "print(df_input.shape)\n",
    "\n",
    "# take only source_url\n",
    "df_input = df_input[[\"source_url\"]]\n",
    "\n",
    "# take only urls with event\n",
    "df_input = df_input[df_input['source_url'].str.contains(r'^https://dice\\.fm/event/.*$', regex=True)]\n",
    "print(df_input.shape)\n",
    "\n",
    "# remove everything after ? in source_url\n",
    "df_input['source_url'] = df_input['source_url'].str.replace(r'\\?.*$', '', regex=True)\n",
    "\n",
    "# drop duplicates\n",
    "df_input = df_input.drop_duplicates()\n",
    "print(df_input.shape)\n",
    "\n",
    "print(df_input.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165579, 15)\n",
      "(165579, 15)\n",
      "(304032, 1)\n",
      "(304031, 1)\n",
      "Index(['url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.DataFrame()\n",
    "\n",
    "df_output_1 = pd.read_excel(\"data/outputs/dice_events_DICE Event Links 1st batch - Sheet1_20241217_171759.xlsx\")\n",
    "print(df_output_1.shape)\n",
    "df_output = pd.concat([df_output, df_output_1], axis=0, ignore_index=True)\n",
    "\n",
    "df_output_2 = pd.read_excel(\"data/outputs/dice_events_Dice Batch 3_20241218_093139.xlsx\")\n",
    "print(df_output_1.shape)\n",
    "df_output = pd.concat([df_output, df_output_2], axis=0, ignore_index=True)\n",
    "\n",
    "df_output = df_output[[\"url\"]]\n",
    "print(df_output.shape)\n",
    "df_output = df_output.drop_duplicates()\n",
    "print(df_output.shape)\n",
    "\n",
    "print(df_output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Index(['source_url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "common_urls = set(df_input['source_url']).intersection(set(df_output['url']))\n",
    "df_new_batch = df_input[~df_input['source_url'].isin(common_urls)]\n",
    "print(df_new_batch.shape)\n",
    "print(df_new_batch.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read latest batch on inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/inputs/dice.fm_event - dice.fm_event.csv\n",
      "(270356, 8)\n",
      "Index(['source_url', 'source_title', 'response_code', 'backlinks_num',\n",
      "       'domains_num', 'last_seen', 'external_num', 'internal_num'],\n",
      "      dtype='object')\n",
      "(270356, 8) (270356, 8)\n",
      "data/inputs/dice.fm_event-csv2 - dice.fm_event-csv2.csv\n",
      "(149648, 8)\n",
      "Index(['source_url', 'source_title', 'response_code', 'backlinks_num',\n",
      "       'domains_num', 'last_seen', 'external_num', 'internal_num'],\n",
      "      dtype='object')\n",
      "(149648, 8) (420004, 8)\n"
     ]
    }
   ],
   "source": [
    "df_latest_full_batch = pd.DataFrame()\n",
    "\n",
    "for input_path in sorted(glob.glob(\"data/inputs/*dice.fm_event*.csv\")):\n",
    "    print(input_path)\n",
    "    df = pd.read_csv(input_path, low_memory=False)\n",
    "    df.columns = ['source_url', 'source_title', 'response_code', 'backlinks_num',\n",
    "       'domains_num', 'last_seen', 'external_num', 'internal_num']\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    df_latest_full_batch = pd.concat([df_latest_full_batch, df], axis=0, ignore_index=True)\n",
    "    print(df.shape, df_latest_full_batch.shape)\n",
    "\n",
    "df_latest_full_batch = df_latest_full_batch[[\"source_url\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420006, 1)\n",
      "Index(['source_url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_latest_full_batch = pd.concat([df_latest_full_batch, df_new_batch], axis=0, ignore_index=True)\n",
    "print(df_latest_full_batch.shape)\n",
    "print(df_latest_full_batch.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123062, 1)\n",
      "Index(['source_url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "common_urls = set(df_latest_full_batch['source_url']).intersection(set(df_output['url']))\n",
    "df_last_batch = df_latest_full_batch[~df_latest_full_batch['source_url'].isin(common_urls)]\n",
    "df_last_batch = df_last_batch.drop_duplicates()\n",
    "print(df_last_batch.shape)\n",
    "print(df_last_batch.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_batch.to_csv(\"data/inputs/Dice_Batch_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
